---
alwaysApply: true
---
# Project Context: User-Configured Automated Intelligence

## 1. Core Value Proposition
- **Identity:** A SaaS that generates dynamic reports based on user configuration (Keywords + Viewpoint) without requiring user prompting.
- **Key Philosophy:** "Zero Prompting" for the end-user. The UI abstracts all prompt engineering.
- **Target Audience:** Professional investors, senior developers, strategists (Time-poor, information-heavy).

## 2. Strict Business Logic (from PRD)
- **Configuration-Driven:** Users only defined `Keywords` and `Viewpoint` (e.g., "Critical", "Optimistic"). Never expose raw prompts to users.
- **Graceful Degradation:** If 1 out of 5 sources fails to crawl, the report MUST still be generated with the remaining 4. Do not fail the whole task. Mark the failed source as `Status: Failed`.
- **Strict Output Format:** The Executive Summary must be **3 bullet points or less**. Use a self-correction loop if the LLM produces more.
- **Async Delivery:** Reports are generated in the background. The frontend must handle long-polling or WebSocket updates with specific status messages (e.g., "Crawling...", "Analyzing...", "Synthesizing...").

## 3. Data Flow (from FLOW.md)
1.  **Client:** Next.js + Shadcn UI -> Config Modal -> Save Config.
2.  **Trigger:** Celery Beat -> Redis -> Celery Worker.
3.  **Execution:** Worker -> Tavily API (Crawl) -> OpenAI (Map-Reduce Analysis) -> PostgreSQL (Save).
4.  **Feedback:** User Feedback -> Pinecone (Vector DB) -> Future Prompt Refinement.

## 4. Operational Constraints
- **Retry Logic:** Max 3 retries with exponential backoff for API calls.
- **Circuit Breaker:** Skip sources that timeout (>10s).
- **Sanitization:** All user inputs (Keywords) must be sanitized before insertion into System Prompts to prevent injection attacks.